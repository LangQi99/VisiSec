/**
 * VisiSec Edge Model Service
 * ç«¯ä¾§è½»é‡çº§æ¨¡å‹æ¨ç†æœåŠ¡
 * 
 * åŠŸèƒ½ï¼š
 * - åœºæ™¯å˜åŒ–æ£€æµ‹
 * - å…³é”®å¸§æå–
 * - æ³¨æ„åŠ›åˆ†æ
 */

import * as tf from '@tensorflow/tfjs'

// æ—¥å¿—è¾…åŠ©å‡½æ•°
const log = (emoji, message, data = null) => {
  console.log(`${emoji} [EdgeModel] ${message}`)
  if (data) {
    console.log('   ğŸ“Š Data:', data)
  }
}

/**
 * åœºæ™¯å˜åŒ–æ£€æµ‹å™¨
 * ä½¿ç”¨ç®€å•çš„å›¾åƒå·®å¼‚ç®—æ³•æ£€æµ‹PPTç¿»é¡µã€ç™½æ¿æ›´æ–°ç­‰
 */
export class SceneChangeDetector {
  constructor() {
    this.previousFrame = null
    this.threshold = 0.15 // å˜åŒ–é˜ˆå€¼ï¼ˆ15%ï¼‰
    this.initialized = false
  }

  /**
   * åˆå§‹åŒ–æ£€æµ‹å™¨
   */
  async initialize() {
    try {
      log('ğŸš€', 'Initializing scene change detector...')
      
      // ç¡®ä¿TensorFlow.jså·²å°±ç»ª
      await tf.ready()
      
      log('âœ…', 'TensorFlow.js backend:', tf.getBackend())
      log('âœ…', 'Scene change detector initialized')
      
      this.initialized = true
      return true
    } catch (error) {
      log('âŒ', 'Failed to initialize scene change detector', error)
      throw error
    }
  }

  /**
   * å°†base64å›¾åƒè½¬æ¢ä¸ºtensor
   */
  async imageToTensor(base64Image) {
    try {
      // åˆ›å»ºImageå…ƒç´ 
      const img = new Image()
      img.src = `data:image/jpeg;base64,${base64Image}`
      
      await new Promise((resolve, reject) => {
        img.onload = resolve
        img.onerror = reject
      })

      // è½¬æ¢ä¸ºtensorå¹¶è°ƒæ•´å¤§å°
      const tensor = tf.browser.fromPixels(img)
        .resizeNearestNeighbor([224, 224]) // ç»Ÿä¸€å°ºå¯¸
        .toFloat()
        .div(255.0) // å½’ä¸€åŒ–åˆ° [0, 1]
      
      return tensor
    } catch (error) {
      log('âŒ', 'Failed to convert image to tensor', error)
      throw error
    }
  }

  /**
   * æ£€æµ‹åœºæ™¯å˜åŒ–
   * @param {string} base64Image - Base64ç¼–ç çš„å›¾åƒ
   * @returns {Object} æ£€æµ‹ç»“æœ
   */
  async detectChange(base64Image) {
    if (!this.initialized) {
      await this.initialize()
    }

    try {
      log('ğŸ”', 'Detecting scene change...')
      
      const currentTensor = await this.imageToTensor(base64Image)

      // ç¬¬ä¸€å¸§ï¼Œä¿å­˜ä¸ºå‚è€ƒ
      if (!this.previousFrame) {
        this.previousFrame = currentTensor
        log('ğŸ“¸', 'First frame captured as reference')
        return {
          changed: false,
          changeRatio: 0,
          isKeyframe: false
        }
      }

      // è®¡ç®—å›¾åƒå·®å¼‚
      const diff = tf.tidy(() => {
        const difference = tf.sub(currentTensor, this.previousFrame)
        const absoluteDiff = tf.abs(difference)
        const meanDiff = tf.mean(absoluteDiff)
        return meanDiff.dataSync()[0]
      })

      const changed = diff > this.threshold
      const isKeyframe = diff > this.threshold * 2 // æ›´æ˜æ˜¾çš„å˜åŒ–æ‰ç®—å…³é”®å¸§

      log('âœ…', `Scene change detection complete`, {
        changeRatio: diff.toFixed(4),
        threshold: this.threshold,
        changed: changed,
        isKeyframe: isKeyframe
      })

      // å¦‚æœæ£€æµ‹åˆ°å˜åŒ–ï¼Œæ›´æ–°å‚è€ƒå¸§
      if (changed) {
        this.previousFrame.dispose() // é‡Šæ”¾æ—§tensor
        this.previousFrame = currentTensor
      } else {
        currentTensor.dispose() // é‡Šæ”¾å½“å‰tensor
      }

      return {
        changed: changed,
        changeRatio: diff,
        isKeyframe: isKeyframe,
        timestamp: Date.now()
      }
    } catch (error) {
      log('âŒ', 'Scene change detection failed', error)
      throw error
    }
  }

  /**
   * é‡ç½®æ£€æµ‹å™¨
   */
  reset() {
    if (this.previousFrame) {
      this.previousFrame.dispose()
      this.previousFrame = null
    }
    log('ğŸ”„', 'Scene change detector reset')
  }

  /**
   * æ¸…ç†èµ„æº
   */
  dispose() {
    this.reset()
    log('ğŸ—‘ï¸', 'Scene change detector disposed')
  }
}

/**
 * ç®€åŒ–çš„æ³¨æ„åŠ›è¯„åˆ†å™¨
 * åŸºäºIMUæ•°æ®å’Œåº”ç”¨çŠ¶æ€è¯„ä¼°ç”¨æˆ·æ³¨æ„åŠ›
 */
export class AttentionScorer {
  constructor() {
    this.initialized = false
  }

  async initialize() {
    try {
      log('ğŸš€', 'Initializing attention scorer...')
      this.initialized = true
      log('âœ…', 'Attention scorer initialized')
      return true
    } catch (error) {
      log('âŒ', 'Failed to initialize attention scorer', error)
      throw error
    }
  }

  /**
   * è®¡ç®—æ³¨æ„åŠ›å¾—åˆ†
   * @param {Object} sensorData - ä¼ æ„Ÿå™¨æ•°æ®
   * @returns {Object} æ³¨æ„åŠ›åˆ†æç»“æœ
   */
  async scoreAttention(sensorData) {
    if (!this.initialized) {
      await this.initialize()
    }

    try {
      log('ğŸ§ ', 'Calculating attention score...')
      
      // åŸºç¡€å¾—åˆ†
      let score = 1.0

      // æ ¹æ®è®¾å¤‡è¿åŠ¨è°ƒæ•´å¾—åˆ†
      if (sensorData.imu && sensorData.imu.analysis) {
        const motion = sensorData.imu.analysis
        
        if (motion.movement === 'active') {
          score -= 0.3 // è®¾å¤‡é¢‘ç¹ç§»åŠ¨ï¼Œå¯èƒ½åˆ†å¿ƒ
          log('ğŸ“‰', 'Score reduced due to active device movement')
        } else if (motion.movement === 'moderate') {
          score -= 0.1
        }
      }

      // æ ¹æ®åº”ç”¨çŠ¶æ€è°ƒæ•´å¾—åˆ†
      if (sensorData.appState && sensorData.appState.analysis) {
        const distraction = sensorData.appState.analysis
        
        if (distraction.distracted) {
          score -= 0.4 // é¢‘ç¹åˆ‡æ¢åº”ç”¨ï¼Œæ³¨æ„åŠ›åˆ†æ•£
          log('ğŸ“‰', 'Score reduced due to app switching')
        }
        
        if (distraction.currentState === 'background') {
          score -= 0.5 // åº”ç”¨åœ¨åå°
          log('ğŸ“‰', 'Score reduced - app in background')
        }
      }

      // ç¡®ä¿å¾—åˆ†åœ¨ [0, 1] èŒƒå›´å†…
      score = Math.max(0, Math.min(1, score))

      const level = score > 0.7 ? 'high' : score > 0.4 ? 'medium' : 'low'
      const color = level === 'high' ? 'green' : level === 'medium' ? 'yellow' : 'red'

      const result = {
        score: score,
        level: level,
        color: color,
        timestamp: Date.now(),
        factors: {
          deviceMotion: sensorData.imu?.analysis?.movement || 'unknown',
          appState: sensorData.appState?.analysis?.currentState || 'unknown',
          distracted: sensorData.appState?.analysis?.distracted || false
        }
      }

      log('âœ…', 'Attention score calculated', result)
      
      return result
    } catch (error) {
      log('âŒ', 'Failed to calculate attention score', error)
      throw error
    }
  }

  /**
   * æ‰¹é‡å¤„ç†æ³¨æ„åŠ›æ•°æ®ï¼Œç”Ÿæˆæ—¶é—´çº¿
   */
  async generateAttentionTimeline(sensorDataArray) {
    try {
      log('ğŸ“Š', `Generating attention timeline for ${sensorDataArray.length} data points...`)
      
      const timeline = []
      
      for (const data of sensorDataArray) {
        const score = await this.scoreAttention(data)
        timeline.push(score)
      }

      // è¯†åˆ«ä½æ³¨æ„åŠ›æ—¶æ®µ
      const lowAttentionPeriods = []
      let periodStart = null

      for (let i = 0; i < timeline.length; i++) {
        if (timeline[i].level === 'low') {
          if (periodStart === null) {
            periodStart = i
          }
        } else {
          if (periodStart !== null) {
            lowAttentionPeriods.push({
              start: periodStart,
              end: i - 1,
              duration: i - periodStart
            })
            periodStart = null
          }
        }
      }

      // å¤„ç†ç»“å°¾çš„ä½æ³¨æ„åŠ›æ—¶æ®µ
      if (periodStart !== null) {
        lowAttentionPeriods.push({
          start: periodStart,
          end: timeline.length - 1,
          duration: timeline.length - periodStart
        })
      }

      const result = {
        timeline: timeline,
        lowAttentionPeriods: lowAttentionPeriods,
        averageScore: timeline.reduce((sum, item) => sum + item.score, 0) / timeline.length
      }

      log('âœ…', 'Attention timeline generated', {
        dataPoints: timeline.length,
        lowPeriods: lowAttentionPeriods.length,
        avgScore: result.averageScore.toFixed(2)
      })

      return result
    } catch (error) {
      log('âŒ', 'Failed to generate attention timeline', error)
      throw error
    }
  }
}

/**
 * OCRæ¨¡æ‹Ÿå™¨ï¼ˆå ä½ç¬¦ï¼‰
 * å®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨Tesseract.jsæˆ–å…¶ä»–OCRåº“
 */
export class SimpleOCR {
  constructor() {
    this.initialized = false
  }

  async initialize() {
    try {
      log('ğŸš€', 'Initializing OCR...')
      // è¿™é‡Œå¯ä»¥åŠ è½½Tesseract.jsæˆ–å…¶ä»–OCRå¼•æ“
      this.initialized = true
      log('âœ…', 'OCR initialized (placeholder)')
      return true
    } catch (error) {
      log('âŒ', 'Failed to initialize OCR', error)
      throw error
    }
  }

  /**
   * ä»å›¾åƒä¸­æå–æ–‡æœ¬
   */
  async extractText(base64Image) {
    if (!this.initialized) {
      await this.initialize()
    }

    try {
      log('ğŸ”', 'Extracting text from image...')
      
      // å ä½ç¬¦å®ç°
      // å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨çœŸå®çš„OCRå¼•æ“
      const mockText = `
æ£€æµ‹åˆ°çš„æ–‡æœ¬ï¼ˆæ¨¡æ‹Ÿï¼‰:
â€¢ äº§å“è·¯çº¿å›¾ Q4 2026
â€¢ æ ¸å¿ƒåŠŸèƒ½ä¼˜å…ˆçº§
â€¢ å¸‚åœºåˆ†æç»“æœ
â€¢ ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’
      `.trim()

      log('âœ…', 'Text extraction complete (simulated)')
      
      return {
        text: mockText,
        confidence: 0.85,
        timestamp: Date.now()
      }
    } catch (error) {
      log('âŒ', 'Failed to extract text', error)
      throw error
    }
  }
}

/**
 * è¾¹ç¼˜æ¨¡å‹ç®¡ç†å™¨
 * ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ç«¯ä¾§æ¨¡å‹
 */
export class EdgeModelManager {
  constructor() {
    this.sceneDetector = new SceneChangeDetector()
    this.attentionScorer = new AttentionScorer()
    this.ocr = new SimpleOCR()
    this.initialized = false
  }

  /**
   * åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹
   */
  async initializeAll() {
    try {
      log('ğŸš€', '='.repeat(60))
      log('ğŸš€', 'Initializing all edge models...')
      log('ğŸš€', '='.repeat(60))
      
      await this.sceneDetector.initialize()
      await this.attentionScorer.initialize()
      await this.ocr.initialize()
      
      this.initialized = true
      
      log('âœ…', '='.repeat(60))
      log('âœ…', 'All edge models initialized successfully!')
      log('âœ…', '='.repeat(60))
      
      return {
        success: true,
        models: {
          sceneDetector: true,
          attentionScorer: true,
          ocr: true
        },
        backend: tf.getBackend()
      }
    } catch (error) {
      log('âŒ', 'Failed to initialize edge models', error)
      throw error
    }
  }

  /**
   * å¤„ç†å•å¸§
   */
  async processFrame(base64Image, sensorData) {
    if (!this.initialized) {
      await this.initializeAll()
    }

    try {
      log('âš™ï¸', 'Processing frame...')
      
      // å¹¶è¡Œå¤„ç†
      const [sceneChange, attentionScore, ocrResult] = await Promise.all([
        this.sceneDetector.detectChange(base64Image),
        this.attentionScorer.scoreAttention(sensorData),
        sceneChange?.isKeyframe ? this.ocr.extractText(base64Image) : null
      ])

      const result = {
        timestamp: Date.now(),
        sceneChange: sceneChange,
        attention: attentionScore,
        ocr: ocrResult,
        isKeyframe: sceneChange.isKeyframe
      }

      log('âœ…', 'Frame processing complete', {
        sceneChanged: sceneChange.changed,
        attentionLevel: attentionScore.level,
        isKeyframe: result.isKeyframe
      })

      return result
    } catch (error) {
      log('âŒ', 'Failed to process frame', error)
      throw error
    }
  }

  /**
   * æ¸…ç†èµ„æº
   */
  dispose() {
    this.sceneDetector.dispose()
    log('ğŸ—‘ï¸', 'Edge model manager disposed')
  }
}

// åˆ›å»ºå•ä¾‹å®ä¾‹
export const edgeModelManager = new EdgeModelManager()
